{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# COCO related libraries \n",
    "from samples.coco import coco\n",
    "\n",
    "#MaskRCNN libraries \n",
    "from mrcnn.config import Config\n",
    "import mrcnn.utils as utils \n",
    "from mrcnn import visualize \n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import MaskRCNN\n",
    "from keras.models import load_model\n",
    "from mrcnn.visualize import display_images\n",
    "from mrcnn.model import log\n",
    "\n",
    "\n",
    "# Misc\n",
    "import os\n",
    "import sys \n",
    "import json\n",
    "import numpy as np\n",
    "import time \n",
    "from PIL import Image, ImageDraw\n",
    "import imgaug \n",
    "from imgaug import augmenters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes in dataset\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Relative path to .h5 weights file \n",
    "WEIGHTS_FILE = None\n",
    "\n",
    "# Relative path to train annotations JSON file\n",
    "TRAIN_ANNOTATIONS_FILE = \"C:/Users/FATTY/MaskRCNN/myMaskRCNN/Train_images/annotations.json\"\n",
    "\n",
    "#  Relative path to directory of tRAIN images \n",
    "TRAIN_ANNOTATIONS_IMAGE_DIR = \"C:/Users/FATTY/MaskRCNN/myMaskRCNN/Train_images\"\n",
    "\n",
    "\n",
    "# Relative path to validation annotations JSON file\n",
    "VALIDATION_ANNOTATIONS_FILE = \"C:/Users/FATTY/MaskRCNN/myMaskRCNN/Val_images/annotations.json\"\n",
    "\n",
    "\n",
    "#  Relative path to directory of VALIDATION images \n",
    "VALIDATION_ANNOTATION_IMAGE_DIR = \"C:/Users/FATTY/MaskRCNN/myMaskRCNN/Val_images\"\n",
    "\n",
    "\n",
    "# Number of epochs to train on \n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "MODEL_NAME = \"model_1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  Additional setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the root directory to the root directiory of MASK RCNN git repo\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save trained models and logs \n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# select which GPU to use \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Declare Training Configurations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myMaskRCNNConfig(coco.CocoConfig):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    #Give the configuration a recognizable name \n",
    "    NAME = \"MaskRCNN_config\"\n",
    "    \n",
    "    # Train on 1 image per GPU \n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1 \n",
    "\n",
    "    # Number of class including background \n",
    "    NUM_CLASSES = 1 + 1\n",
    "\n",
    "    # Min and Max image dimensions\n",
    "    IMAGE_MIN_DIM = 1152\n",
    "    IMAGE_MIN_DIM = 1280\n",
    "\n",
    "    # You can experiment with this number to see if it improves training \n",
    "    STEPS_PER_EPOCH = 80\n",
    "\n",
    "    # This is how often validation is run, if you are using too much hard drive space on saved models try to make this value larger\n",
    "    VALIDATION_STEPS = 100 \n",
    "\n",
    "    # Matterport use resnet101, here we downsize to fit our graphic card \n",
    "    BACKBONE = \"resnet101\" \n",
    "\n",
    "\n",
    "    # RPN ANCHOR SCALES \n",
    "    RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)\n",
    "\n",
    "    # changed to 512 because that's the number use in the original MaskRCNN paper \n",
    "    \n",
    "    TRAIN_ROIS_PER_IMAGE = 200\n",
    "    MAX_GT_INSTANCES = 114\n",
    "    POST_NMS_ROIS_INFERENCE = 1000\n",
    "    POST_NMS_ROIS_TRAINING = 2000\n",
    "\n",
    "    DETECTION_MAX_INSTANCES = 125\n",
    "    DETECTION_MIN_CONFIDENCE = 0.8\n",
    "    \n",
    "    MINI_MASK_SHAPE = (128, 128)\n",
    "    MAX_GT_INSTANCES = 125\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Create an instance of the myMaskRCNNConfig class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = myMaskRCNNConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Let's display all config values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        125\n",
      "DETECTION_MIN_CONFIDENCE       0.8\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  1280\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               125\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (128, 128)\n",
      "NAME                           MaskRCNN_config\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                90\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               100\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " # Create class to load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoLikeDataset(utils.Dataset):\n",
    "    \"\"\" Generates a COCO-like dataset, i.e. an image dataset annotated in the style of the COCO dataset.\n",
    "        See http://cocodataset.org/#home for more information.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_data(self, annotation_json, images_dir):\n",
    "        \"\"\" Load the coco-like dataset from json\n",
    "        Args:\n",
    "            annotation_json: The path to the coco annotations json file\n",
    "            images_dir: The directory holding the images referred to by the json file\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        # Load json from file\n",
    "        json_file = open(annotation_json)\n",
    "        coco_json = json.load(json_file)\n",
    "        json_file.close()\n",
    "        \n",
    "        # Add the class names using the base method from utils.Dataset\n",
    "        source_name = \"coco_like\"\n",
    "        for category in coco_json['categories']:\n",
    "            class_id = category['id']\n",
    "            class_name = category['name']\n",
    "            if class_id < 1:\n",
    "                print('Error: Class id for \"{}\" cannot be less than one. (0 is reserved for the background)'.format(class_name))\n",
    "                return\n",
    "            \n",
    "            self.add_class(source_name, class_id, class_name)\n",
    "        \n",
    "        # Get all annotations\n",
    "        annotations = {}\n",
    "        for annotation in coco_json['annotations']:\n",
    "            image_id = annotation['image_id']\n",
    "            if image_id not in annotations:\n",
    "                annotations[image_id] = []\n",
    "            annotations[image_id].append(annotation)\n",
    "        \n",
    "        # Get all images and add them to the dataset\n",
    "        seen_images = {}\n",
    "        for image in coco_json['images']:\n",
    "            image_id = image['id']\n",
    "            if image_id in seen_images:\n",
    "                print(\"Warning: Skipping duplicate image id: {}\".format(image))\n",
    "            else:\n",
    "                seen_images[image_id] = image\n",
    "                try:\n",
    "                    image_file_name = image['file_name']\n",
    "                    image_width = image['width']\n",
    "                    image_height = image['height']\n",
    "                except KeyError as key:\n",
    "                    print(\"Warning: Skipping image (id: {}) with missing key: {}\".format(image_id, key))\n",
    "                \n",
    "                image_path = os.path.abspath(os.path.join(images_dir, image_file_name))\n",
    "                image_annotations = annotations[image_id]\n",
    "                \n",
    "                # Add the image using the base method from utils.Dataset\n",
    "                self.add_image(\n",
    "                    source=source_name,\n",
    "                    image_id=image_id,\n",
    "                    path=image_path,\n",
    "                    width=image_width,\n",
    "                    height=image_height,\n",
    "                    annotations=image_annotations\n",
    "                )\n",
    "                \n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\" Load instance masks for the given image.\n",
    "        MaskRCNN expects masks in the form of a bitmap [height, width, instances].\n",
    "        Args:\n",
    "            image_id: The id of the image to load masks for\n",
    "        Returns:\n",
    "            masks: A bool array of shape [height, width, instance count] with\n",
    "                one mask per instance.\n",
    "            class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        image_info = self.image_info[image_id]\n",
    "        annotations = image_info['annotations']\n",
    "        instance_masks = []\n",
    "        class_ids = []\n",
    "        \n",
    "        for annotation in annotations:\n",
    "            class_id = annotation['category_id']\n",
    "            mask = Image.new('1', (image_info['width'], image_info['height']))\n",
    "            mask_draw = ImageDraw.ImageDraw(mask, '1')\n",
    "            for segmentation in annotation['segmentation']:\n",
    "                mask_draw.polygon(segmentation, fill=1)\n",
    "                bool_array = np.array(mask) > 0\n",
    "                instance_masks.append(bool_array)\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "        mask = np.dstack(instance_masks)\n",
    "        class_ids = np.array(class_ids, dtype=np.int32)\n",
    "        \n",
    "        return mask, class_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load train and validation datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CocoLikeDataset()\n",
    "dataset_train.load_data(TRAIN_ANNOTATIONS_FILE, TRAIN_ANNOTATIONS_IMAGE_DIR)\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_val = CocoLikeDataset()\n",
    "dataset_val.load_data(VALIDATION_ANNOTATIONS_FILE, VALIDATION_ANNOTATION_IMAGE_DIR)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build MaskRCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:515: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:72: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4048: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1897: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3878: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1993: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\FATTY\\MaskRCNN\\myMaskRCNN\\mrcnn\\model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\FATTY\\MaskRCNN\\myMaskRCNN\\mrcnn\\utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\FATTY\\MaskRCNN\\myMaskRCNN\\mrcnn\\model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    }
   ],
   "source": [
    "# Create model in training model\n",
    "model = modellib.MaskRCNN(mode = \"training\", config = myMaskRCNNConfig() , model_dir = MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load weights into model if weights file is not None \n",
    "This is meant to be used if you are refining on a set of preexisting weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WEIGHTS_FILE is not None:\n",
    "    model.load_weights(WEIGHTS_FILE, by_name = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model \n",
    "\n",
    "The model after each epoch will be saved in the logs folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: C:\\Users\\FATTY\\MaskRCNN\\myMaskRCNN\\logs\\maskrcnn_config20200724T1219\\mask_rcnn_maskrcnn_config_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\keras\\optimizers.py:782: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\keras\\callbacks.py:804: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\FATTY\\Anaconda\\lib\\site-packages\\keras\\callbacks.py:807: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 5077s 56s/step - loss: 5.7106 - rpn_class_loss: 1.0696 - rpn_bbox_loss: 2.7990 - mrcnn_class_loss: 0.4221 - mrcnn_bbox_loss: 1.0560 - mrcnn_mask_loss: 0.3640 - val_loss: 9.3568 - val_rpn_class_loss: 4.3924 - val_rpn_bbox_loss: 3.0236 - val_mrcnn_class_loss: 0.3387 - val_mrcnn_bbox_loss: 0.8431 - val_mrcnn_mask_loss: 0.7591\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 3831s 43s/step - loss: 2.2756 - rpn_class_loss: 0.2108 - rpn_bbox_loss: 0.9398 - mrcnn_class_loss: 0.3753 - mrcnn_bbox_loss: 0.6447 - mrcnn_mask_loss: 0.1049 - val_loss: 7.7253 - val_rpn_class_loss: 3.1686 - val_rpn_bbox_loss: 2.0888 - val_mrcnn_class_loss: 0.2996 - val_mrcnn_bbox_loss: 0.8531 - val_mrcnn_mask_loss: 1.3152\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 3930s 44s/step - loss: 2.0349 - rpn_class_loss: 0.2456 - rpn_bbox_loss: 0.8502 - mrcnn_class_loss: 0.3154 - mrcnn_bbox_loss: 0.5927 - mrcnn_mask_loss: 0.0309 - val_loss: 7.8346 - val_rpn_class_loss: 3.3574 - val_rpn_bbox_loss: 1.7808 - val_mrcnn_class_loss: 0.1821 - val_mrcnn_bbox_loss: 0.7827 - val_mrcnn_mask_loss: 1.7317\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 3708s 41s/step - loss: 2.1608 - rpn_class_loss: 0.2631 - rpn_bbox_loss: 0.9268 - mrcnn_class_loss: 0.3674 - mrcnn_bbox_loss: 0.5778 - mrcnn_mask_loss: 0.0258 - val_loss: 7.2806 - val_rpn_class_loss: 2.3881 - val_rpn_bbox_loss: 1.3294 - val_mrcnn_class_loss: 0.1866 - val_mrcnn_bbox_loss: 0.9676 - val_mrcnn_mask_loss: 2.4089\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 3885s 43s/step - loss: 1.8557 - rpn_class_loss: 0.1873 - rpn_bbox_loss: 0.7535 - mrcnn_class_loss: 0.3495 - mrcnn_bbox_loss: 0.5469 - mrcnn_mask_loss: 0.0185 - val_loss: 7.6630 - val_rpn_class_loss: 3.3179 - val_rpn_bbox_loss: 1.5364 - val_mrcnn_class_loss: 0.2783 - val_mrcnn_bbox_loss: 0.7520 - val_mrcnn_mask_loss: 1.7784\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 3769s 42s/step - loss: 1.9149 - rpn_class_loss: 0.1864 - rpn_bbox_loss: 0.8078 - mrcnn_class_loss: 0.3377 - mrcnn_bbox_loss: 0.5660 - mrcnn_mask_loss: 0.0170 - val_loss: 9.5871 - val_rpn_class_loss: 4.4106 - val_rpn_bbox_loss: 1.8941 - val_mrcnn_class_loss: 0.4817 - val_mrcnn_bbox_loss: 0.6743 - val_mrcnn_mask_loss: 2.1263\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 3808s 42s/step - loss: 2.1625 - rpn_class_loss: 0.2877 - rpn_bbox_loss: 0.9569 - mrcnn_class_loss: 0.3516 - mrcnn_bbox_loss: 0.5519 - mrcnn_mask_loss: 0.0145 - val_loss: 8.3271 - val_rpn_class_loss: 2.8205 - val_rpn_bbox_loss: 1.6266 - val_mrcnn_class_loss: 0.9149 - val_mrcnn_bbox_loss: 0.9054 - val_mrcnn_mask_loss: 2.0597\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 3649s 41s/step - loss: 1.7987 - rpn_class_loss: 0.1105 - rpn_bbox_loss: 0.7930 - mrcnn_class_loss: 0.3599 - mrcnn_bbox_loss: 0.5220 - mrcnn_mask_loss: 0.0132 - val_loss: 10.7216 - val_rpn_class_loss: 4.0177 - val_rpn_bbox_loss: 2.4043 - val_mrcnn_class_loss: 0.2615 - val_mrcnn_bbox_loss: 0.8755 - val_mrcnn_mask_loss: 3.1625\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 3672s 41s/step - loss: 1.9429 - rpn_class_loss: 0.2141 - rpn_bbox_loss: 0.8774 - mrcnn_class_loss: 0.3276 - mrcnn_bbox_loss: 0.5113 - mrcnn_mask_loss: 0.0126 - val_loss: 8.8919 - val_rpn_class_loss: 3.5551 - val_rpn_bbox_loss: 1.9311 - val_mrcnn_class_loss: 0.4497 - val_mrcnn_bbox_loss: 0.7213 - val_mrcnn_mask_loss: 2.2347\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 3603s 40s/step - loss: 1.8807 - rpn_class_loss: 0.2047 - rpn_bbox_loss: 0.8101 - mrcnn_class_loss: 0.3313 - mrcnn_bbox_loss: 0.5212 - mrcnn_mask_loss: 0.0134 - val_loss: 9.2416 - val_rpn_class_loss: 3.3181 - val_rpn_bbox_loss: 2.1417 - val_mrcnn_class_loss: 0.4139 - val_mrcnn_bbox_loss: 0.7843 - val_mrcnn_mask_loss: 2.5834\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 3654s 41s/step - loss: 2.0508 - rpn_class_loss: 0.2238 - rpn_bbox_loss: 0.9518 - mrcnn_class_loss: 0.3486 - mrcnn_bbox_loss: 0.5151 - mrcnn_mask_loss: 0.0116 - val_loss: 8.8563 - val_rpn_class_loss: 2.7897 - val_rpn_bbox_loss: 1.7845 - val_mrcnn_class_loss: 0.3933 - val_mrcnn_bbox_loss: 0.9674 - val_mrcnn_mask_loss: 2.9214\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 3688s 41s/step - loss: 1.8345 - rpn_class_loss: 0.2095 - rpn_bbox_loss: 0.7670 - mrcnn_class_loss: 0.3421 - mrcnn_bbox_loss: 0.5044 - mrcnn_mask_loss: 0.0115 - val_loss: 10.0196 - val_rpn_class_loss: 3.4618 - val_rpn_bbox_loss: 2.2120 - val_mrcnn_class_loss: 0.2842 - val_mrcnn_bbox_loss: 0.8180 - val_mrcnn_mask_loss: 3.2435\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 3705s 41s/step - loss: 1.9749 - rpn_class_loss: 0.1961 - rpn_bbox_loss: 0.9059 - mrcnn_class_loss: 0.3231 - mrcnn_bbox_loss: 0.5371 - mrcnn_mask_loss: 0.0127 - val_loss: 8.1909 - val_rpn_class_loss: 3.0836 - val_rpn_bbox_loss: 1.8475 - val_mrcnn_class_loss: 0.5478 - val_mrcnn_bbox_loss: 0.7183 - val_mrcnn_mask_loss: 1.9938\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 3569s 40s/step - loss: 1.7551 - rpn_class_loss: 0.1852 - rpn_bbox_loss: 0.7501 - mrcnn_class_loss: 0.3125 - mrcnn_bbox_loss: 0.4963 - mrcnn_mask_loss: 0.0110 - val_loss: 8.7702 - val_rpn_class_loss: 2.7751 - val_rpn_bbox_loss: 1.5750 - val_mrcnn_class_loss: 0.4820 - val_mrcnn_bbox_loss: 0.9028 - val_mrcnn_mask_loss: 3.0352\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 3705s 41s/step - loss: 1.9374 - rpn_class_loss: 0.2103 - rpn_bbox_loss: 0.8687 - mrcnn_class_loss: 0.3542 - mrcnn_bbox_loss: 0.4934 - mrcnn_mask_loss: 0.0110 - val_loss: 8.6775 - val_rpn_class_loss: 2.9008 - val_rpn_bbox_loss: 1.6870 - val_mrcnn_class_loss: 0.2639 - val_mrcnn_bbox_loss: 0.7413 - val_mrcnn_mask_loss: 3.0845\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 3618s 40s/step - loss: 1.8053 - rpn_class_loss: 0.1471 - rpn_bbox_loss: 0.8100 - mrcnn_class_loss: 0.3440 - mrcnn_bbox_loss: 0.4922 - mrcnn_mask_loss: 0.0120 - val_loss: 10.7262 - val_rpn_class_loss: 3.8207 - val_rpn_bbox_loss: 2.1123 - val_mrcnn_class_loss: 0.8790 - val_mrcnn_bbox_loss: 0.7697 - val_mrcnn_mask_loss: 3.1444\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 3679s 41s/step - loss: 1.8516 - rpn_class_loss: 0.2102 - rpn_bbox_loss: 0.7837 - mrcnn_class_loss: 0.3299 - mrcnn_bbox_loss: 0.5165 - mrcnn_mask_loss: 0.0112 - val_loss: 9.8358 - val_rpn_class_loss: 3.0819 - val_rpn_bbox_loss: 2.2985 - val_mrcnn_class_loss: 0.4877 - val_mrcnn_bbox_loss: 0.7134 - val_mrcnn_mask_loss: 3.2544\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 3635s 40s/step - loss: 1.9052 - rpn_class_loss: 0.1613 - rpn_bbox_loss: 0.9040 - mrcnn_class_loss: 0.3397 - mrcnn_bbox_loss: 0.4890 - mrcnn_mask_loss: 0.0113 - val_loss: 9.2118 - val_rpn_class_loss: 3.4694 - val_rpn_bbox_loss: 2.5750 - val_mrcnn_class_loss: 0.2632 - val_mrcnn_bbox_loss: 0.6129 - val_mrcnn_mask_loss: 2.2913\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 3668s 41s/step - loss: 1.8097 - rpn_class_loss: 0.1328 - rpn_bbox_loss: 0.8491 - mrcnn_class_loss: 0.3375 - mrcnn_bbox_loss: 0.4799 - mrcnn_mask_loss: 0.0103 - val_loss: 7.9899 - val_rpn_class_loss: 2.8002 - val_rpn_bbox_loss: 1.9615 - val_mrcnn_class_loss: 0.4012 - val_mrcnn_bbox_loss: 0.6593 - val_mrcnn_mask_loss: 2.1677\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 3625s 40s/step - loss: 1.9498 - rpn_class_loss: 0.2556 - rpn_bbox_loss: 0.8471 - mrcnn_class_loss: 0.3287 - mrcnn_bbox_loss: 0.5066 - mrcnn_mask_loss: 0.0119 - val_loss: 10.2983 - val_rpn_class_loss: 3.7746 - val_rpn_bbox_loss: 2.5199 - val_mrcnn_class_loss: 0.4944 - val_mrcnn_bbox_loss: 0.7191 - val_mrcnn_mask_loss: 2.7904\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 3660s 41s/step - loss: 1.7455 - rpn_class_loss: 0.1304 - rpn_bbox_loss: 0.7686 - mrcnn_class_loss: 0.3304 - mrcnn_bbox_loss: 0.5046 - mrcnn_mask_loss: 0.0115 - val_loss: 10.0290 - val_rpn_class_loss: 3.2195 - val_rpn_bbox_loss: 2.3861 - val_mrcnn_class_loss: 0.2504 - val_mrcnn_bbox_loss: 0.7165 - val_mrcnn_mask_loss: 3.4564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "90/90 [==============================] - 3614s 40s/step - loss: 2.1122 - rpn_class_loss: 0.2687 - rpn_bbox_loss: 0.9732 - mrcnn_class_loss: 0.3382 - mrcnn_bbox_loss: 0.5219 - mrcnn_mask_loss: 0.0102 - val_loss: 10.8816 - val_rpn_class_loss: 4.0336 - val_rpn_bbox_loss: 2.2788 - val_mrcnn_class_loss: 0.3443 - val_mrcnn_bbox_loss: 0.8092 - val_mrcnn_mask_loss: 3.4158\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 3613s 40s/step - loss: 1.6763 - rpn_class_loss: 0.1323 - rpn_bbox_loss: 0.7039 - mrcnn_class_loss: 0.3458 - mrcnn_bbox_loss: 0.4821 - mrcnn_mask_loss: 0.0122 - val_loss: 10.1596 - val_rpn_class_loss: 3.8149 - val_rpn_bbox_loss: 2.3374 - val_mrcnn_class_loss: 0.1941 - val_mrcnn_bbox_loss: 0.6733 - val_mrcnn_mask_loss: 3.1398\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 3712s 41s/step - loss: 1.6394 - rpn_class_loss: 0.1725 - rpn_bbox_loss: 0.6914 - mrcnn_class_loss: 0.2930 - mrcnn_bbox_loss: 0.4736 - mrcnn_mask_loss: 0.0089 - val_loss: 10.2718 - val_rpn_class_loss: 3.3486 - val_rpn_bbox_loss: 2.0331 - val_mrcnn_class_loss: 0.2802 - val_mrcnn_bbox_loss: 0.7120 - val_mrcnn_mask_loss: 3.8979\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 3594s 40s/step - loss: 2.1382 - rpn_class_loss: 0.2562 - rpn_bbox_loss: 1.0337 - mrcnn_class_loss: 0.3164 - mrcnn_bbox_loss: 0.5205 - mrcnn_mask_loss: 0.0114 - val_loss: 10.3770 - val_rpn_class_loss: 3.1385 - val_rpn_bbox_loss: 1.9827 - val_mrcnn_class_loss: 0.2820 - val_mrcnn_bbox_loss: 0.7713 - val_mrcnn_mask_loss: 4.2026\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 3608s 40s/step - loss: 1.8124 - rpn_class_loss: 0.2055 - rpn_bbox_loss: 0.8175 - mrcnn_class_loss: 0.3029 - mrcnn_bbox_loss: 0.4755 - mrcnn_mask_loss: 0.0111 - val_loss: 9.9437 - val_rpn_class_loss: 3.5562 - val_rpn_bbox_loss: 1.9359 - val_mrcnn_class_loss: 0.3009 - val_mrcnn_bbox_loss: 0.7468 - val_mrcnn_mask_loss: 3.4039\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 3656s 41s/step - loss: 1.6494 - rpn_class_loss: 0.1259 - rpn_bbox_loss: 0.7285 - mrcnn_class_loss: 0.3220 - mrcnn_bbox_loss: 0.4632 - mrcnn_mask_loss: 0.0098 - val_loss: 10.1079 - val_rpn_class_loss: 3.3912 - val_rpn_bbox_loss: 1.8076 - val_mrcnn_class_loss: 0.5837 - val_mrcnn_bbox_loss: 0.8002 - val_mrcnn_mask_loss: 3.5251\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 3623s 40s/step - loss: 1.8846 - rpn_class_loss: 0.2317 - rpn_bbox_loss: 0.8102 - mrcnn_class_loss: 0.3308 - mrcnn_bbox_loss: 0.5012 - mrcnn_mask_loss: 0.0107 - val_loss: 10.6990 - val_rpn_class_loss: 3.8887 - val_rpn_bbox_loss: 2.3388 - val_mrcnn_class_loss: 0.4010 - val_mrcnn_bbox_loss: 0.7773 - val_mrcnn_mask_loss: 3.2933\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 3674s 41s/step - loss: 1.8865 - rpn_class_loss: 0.2338 - rpn_bbox_loss: 0.8383 - mrcnn_class_loss: 0.3116 - mrcnn_bbox_loss: 0.4922 - mrcnn_mask_loss: 0.0105 - val_loss: 10.4766 - val_rpn_class_loss: 3.4353 - val_rpn_bbox_loss: 2.1589 - val_mrcnn_class_loss: 0.3920 - val_mrcnn_bbox_loss: 0.8982 - val_mrcnn_mask_loss: 3.5922\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 3623s 40s/step - loss: 1.8304 - rpn_class_loss: 0.1812 - rpn_bbox_loss: 0.7959 - mrcnn_class_loss: 0.3454 - mrcnn_bbox_loss: 0.4977 - mrcnn_mask_loss: 0.0102 - val_loss: 8.0199 - val_rpn_class_loss: 2.7671 - val_rpn_bbox_loss: 1.7481 - val_mrcnn_class_loss: 0.2225 - val_mrcnn_bbox_loss: 0.6739 - val_mrcnn_mask_loss: 2.6082\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 3654s 41s/step - loss: 1.6346 - rpn_class_loss: 0.1282 - rpn_bbox_loss: 0.6856 - mrcnn_class_loss: 0.3228 - mrcnn_bbox_loss: 0.4870 - mrcnn_mask_loss: 0.0109 - val_loss: 11.4620 - val_rpn_class_loss: 3.9989 - val_rpn_bbox_loss: 2.2832 - val_mrcnn_class_loss: 0.2245 - val_mrcnn_bbox_loss: 0.9711 - val_mrcnn_mask_loss: 3.9842\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 3695s 41s/step - loss: 1.7009 - rpn_class_loss: 0.1865 - rpn_bbox_loss: 0.7247 - mrcnn_class_loss: 0.2949 - mrcnn_bbox_loss: 0.4843 - mrcnn_mask_loss: 0.0105 - val_loss: 10.1103 - val_rpn_class_loss: 3.4294 - val_rpn_bbox_loss: 1.9185 - val_mrcnn_class_loss: 0.5830 - val_mrcnn_bbox_loss: 0.7220 - val_mrcnn_mask_loss: 3.4573\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 3634s 40s/step - loss: 1.9366 - rpn_class_loss: 0.2296 - rpn_bbox_loss: 0.8931 - mrcnn_class_loss: 0.3117 - mrcnn_bbox_loss: 0.4905 - mrcnn_mask_loss: 0.0117 - val_loss: 9.0782 - val_rpn_class_loss: 3.3741 - val_rpn_bbox_loss: 1.7201 - val_mrcnn_class_loss: 0.4119 - val_mrcnn_bbox_loss: 0.7740 - val_mrcnn_mask_loss: 2.7980\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 3612s 40s/step - loss: 1.7250 - rpn_class_loss: 0.2089 - rpn_bbox_loss: 0.7170 - mrcnn_class_loss: 0.3189 - mrcnn_bbox_loss: 0.4700 - mrcnn_mask_loss: 0.0101 - val_loss: 9.6878 - val_rpn_class_loss: 2.9003 - val_rpn_bbox_loss: 1.6807 - val_mrcnn_class_loss: 0.2438 - val_mrcnn_bbox_loss: 0.9125 - val_mrcnn_mask_loss: 3.9504\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 3692s 41s/step - loss: 1.7449 - rpn_class_loss: 0.1685 - rpn_bbox_loss: 0.8036 - mrcnn_class_loss: 0.2965 - mrcnn_bbox_loss: 0.4666 - mrcnn_mask_loss: 0.0096 - val_loss: 10.2983 - val_rpn_class_loss: 2.7266 - val_rpn_bbox_loss: 1.6685 - val_mrcnn_class_loss: 0.5330 - val_mrcnn_bbox_loss: 0.9079 - val_mrcnn_mask_loss: 4.4623\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 3752s 42s/step - loss: 1.6103 - rpn_class_loss: 0.1471 - rpn_bbox_loss: 0.6826 - mrcnn_class_loss: 0.2996 - mrcnn_bbox_loss: 0.4701 - mrcnn_mask_loss: 0.0109 - val_loss: 9.9458 - val_rpn_class_loss: 3.1005 - val_rpn_bbox_loss: 1.8105 - val_mrcnn_class_loss: 0.8103 - val_mrcnn_bbox_loss: 0.8085 - val_mrcnn_mask_loss: 3.4160\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 3648s 41s/step - loss: 1.7407 - rpn_class_loss: 0.1852 - rpn_bbox_loss: 0.7637 - mrcnn_class_loss: 0.3074 - mrcnn_bbox_loss: 0.4741 - mrcnn_mask_loss: 0.0103 - val_loss: 9.7653 - val_rpn_class_loss: 2.8787 - val_rpn_bbox_loss: 1.7921 - val_mrcnn_class_loss: 0.3066 - val_mrcnn_bbox_loss: 0.7663 - val_mrcnn_mask_loss: 4.0216\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 3659s 41s/step - loss: 1.6296 - rpn_class_loss: 0.1584 - rpn_bbox_loss: 0.6924 - mrcnn_class_loss: 0.2982 - mrcnn_bbox_loss: 0.4671 - mrcnn_mask_loss: 0.0133 - val_loss: 11.9359 - val_rpn_class_loss: 3.8529 - val_rpn_bbox_loss: 2.2340 - val_mrcnn_class_loss: 0.4609 - val_mrcnn_bbox_loss: 0.9345 - val_mrcnn_mask_loss: 4.4536\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 3645s 41s/step - loss: 1.6119 - rpn_class_loss: 0.1323 - rpn_bbox_loss: 0.7270 - mrcnn_class_loss: 0.2956 - mrcnn_bbox_loss: 0.4456 - mrcnn_mask_loss: 0.0113 - val_loss: 10.5132 - val_rpn_class_loss: 3.4843 - val_rpn_bbox_loss: 2.1113 - val_mrcnn_class_loss: 0.3244 - val_mrcnn_bbox_loss: 0.8053 - val_mrcnn_mask_loss: 3.7878\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 3703s 41s/step - loss: 2.0110 - rpn_class_loss: 0.2267 - rpn_bbox_loss: 0.9463 - mrcnn_class_loss: 0.3455 - mrcnn_bbox_loss: 0.4811 - mrcnn_mask_loss: 0.0114 - val_loss: 8.1691 - val_rpn_class_loss: 2.5139 - val_rpn_bbox_loss: 1.7374 - val_mrcnn_class_loss: 0.4301 - val_mrcnn_bbox_loss: 0.7438 - val_mrcnn_mask_loss: 2.7439\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 3637s 40s/step - loss: 1.7968 - rpn_class_loss: 0.1757 - rpn_bbox_loss: 0.8091 - mrcnn_class_loss: 0.3319 - mrcnn_bbox_loss: 0.4695 - mrcnn_mask_loss: 0.0106 - val_loss: 9.9550 - val_rpn_class_loss: 2.9615 - val_rpn_bbox_loss: 1.9461 - val_mrcnn_class_loss: 0.3678 - val_mrcnn_bbox_loss: 0.8348 - val_mrcnn_mask_loss: 3.8448\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 3605s 40s/step - loss: 1.6636 - rpn_class_loss: 0.1556 - rpn_bbox_loss: 0.7391 - mrcnn_class_loss: 0.3131 - mrcnn_bbox_loss: 0.4454 - mrcnn_mask_loss: 0.0105 - val_loss: 10.5655 - val_rpn_class_loss: 2.8565 - val_rpn_bbox_loss: 2.0140 - val_mrcnn_class_loss: 0.3198 - val_mrcnn_bbox_loss: 0.9206 - val_mrcnn_mask_loss: 4.4545\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 3596s 40s/step - loss: 1.5442 - rpn_class_loss: 0.1360 - rpn_bbox_loss: 0.6446 - mrcnn_class_loss: 0.2874 - mrcnn_bbox_loss: 0.4652 - mrcnn_mask_loss: 0.0110 - val_loss: 10.2722 - val_rpn_class_loss: 3.1849 - val_rpn_bbox_loss: 2.2291 - val_mrcnn_class_loss: 0.4495 - val_mrcnn_bbox_loss: 0.8230 - val_mrcnn_mask_loss: 3.5857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "90/90 [==============================] - 3667s 41s/step - loss: 1.8920 - rpn_class_loss: 0.1981 - rpn_bbox_loss: 0.9216 - mrcnn_class_loss: 0.3015 - mrcnn_bbox_loss: 0.4602 - mrcnn_mask_loss: 0.0106 - val_loss: 8.7552 - val_rpn_class_loss: 2.8768 - val_rpn_bbox_loss: 2.1569 - val_mrcnn_class_loss: 0.2392 - val_mrcnn_bbox_loss: 0.7559 - val_mrcnn_mask_loss: 2.7263\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 3563s 40s/step - loss: 1.6481 - rpn_class_loss: 0.1405 - rpn_bbox_loss: 0.7163 - mrcnn_class_loss: 0.3073 - mrcnn_bbox_loss: 0.4729 - mrcnn_mask_loss: 0.0111 - val_loss: 8.9513 - val_rpn_class_loss: 2.8081 - val_rpn_bbox_loss: 1.9324 - val_mrcnn_class_loss: 0.3470 - val_mrcnn_bbox_loss: 0.7473 - val_mrcnn_mask_loss: 3.1165\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 3687s 41s/step - loss: 1.6980 - rpn_class_loss: 0.1583 - rpn_bbox_loss: 0.7506 - mrcnn_class_loss: 0.3174 - mrcnn_bbox_loss: 0.4612 - mrcnn_mask_loss: 0.0106 - val_loss: 9.7286 - val_rpn_class_loss: 3.1207 - val_rpn_bbox_loss: 2.1151 - val_mrcnn_class_loss: 0.2106 - val_mrcnn_bbox_loss: 0.8091 - val_mrcnn_mask_loss: 3.4730\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 3624s 40s/step - loss: 1.5414 - rpn_class_loss: 0.1676 - rpn_bbox_loss: 0.6197 - mrcnn_class_loss: 0.2968 - mrcnn_bbox_loss: 0.4467 - mrcnn_mask_loss: 0.0106 - val_loss: 12.2607 - val_rpn_class_loss: 3.0048 - val_rpn_bbox_loss: 2.1831 - val_mrcnn_class_loss: 0.2963 - val_mrcnn_bbox_loss: 0.9917 - val_mrcnn_mask_loss: 5.7848\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 3618s 40s/step - loss: 1.6764 - rpn_class_loss: 0.1663 - rpn_bbox_loss: 0.7837 - mrcnn_class_loss: 0.2709 - mrcnn_bbox_loss: 0.4457 - mrcnn_mask_loss: 0.0097 - val_loss: 10.1808 - val_rpn_class_loss: 3.1797 - val_rpn_bbox_loss: 1.7980 - val_mrcnn_class_loss: 0.5035 - val_mrcnn_bbox_loss: 0.8182 - val_mrcnn_mask_loss: 3.8815\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 3630s 40s/step - loss: 1.6095 - rpn_class_loss: 0.1654 - rpn_bbox_loss: 0.6791 - mrcnn_class_loss: 0.3094 - mrcnn_bbox_loss: 0.4454 - mrcnn_mask_loss: 0.0102 - val_loss: 9.4796 - val_rpn_class_loss: 3.1358 - val_rpn_bbox_loss: 1.7733 - val_mrcnn_class_loss: 0.6527 - val_mrcnn_bbox_loss: 0.8184 - val_mrcnn_mask_loss: 3.0993\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 3651s 41s/step - loss: 1.5613 - rpn_class_loss: 0.1475 - rpn_bbox_loss: 0.6975 - mrcnn_class_loss: 0.2655 - mrcnn_bbox_loss: 0.4387 - mrcnn_mask_loss: 0.0122 - val_loss: 9.7556 - val_rpn_class_loss: 2.7919 - val_rpn_bbox_loss: 1.7423 - val_mrcnn_class_loss: 0.4094 - val_mrcnn_bbox_loss: 0.8685 - val_mrcnn_mask_loss: 3.9435\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 3616s 40s/step - loss: 1.5076 - rpn_class_loss: 0.1290 - rpn_bbox_loss: 0.6495 - mrcnn_class_loss: 0.2723 - mrcnn_bbox_loss: 0.4464 - mrcnn_mask_loss: 0.0104 - val_loss: 9.5304 - val_rpn_class_loss: 2.8327 - val_rpn_bbox_loss: 1.7810 - val_mrcnn_class_loss: 0.3195 - val_mrcnn_bbox_loss: 0.7777 - val_mrcnn_mask_loss: 3.8195\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 3692s 41s/step - loss: 1.5874 - rpn_class_loss: 0.1829 - rpn_bbox_loss: 0.6994 - mrcnn_class_loss: 0.2610 - mrcnn_bbox_loss: 0.4338 - mrcnn_mask_loss: 0.0102 - val_loss: 8.7699 - val_rpn_class_loss: 2.4237 - val_rpn_bbox_loss: 1.5909 - val_mrcnn_class_loss: 0.2649 - val_mrcnn_bbox_loss: 0.8382 - val_mrcnn_mask_loss: 3.6522\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 3586s 40s/step - loss: 1.5100 - rpn_class_loss: 0.1413 - rpn_bbox_loss: 0.5892 - mrcnn_class_loss: 0.2990 - mrcnn_bbox_loss: 0.4690 - mrcnn_mask_loss: 0.0114 - val_loss: 9.2659 - val_rpn_class_loss: 2.2872 - val_rpn_bbox_loss: 1.5027 - val_mrcnn_class_loss: 0.4190 - val_mrcnn_bbox_loss: 0.8250 - val_mrcnn_mask_loss: 4.2321\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 3715s 41s/step - loss: 1.4599 - rpn_class_loss: 0.1006 - rpn_bbox_loss: 0.6509 - mrcnn_class_loss: 0.2654 - mrcnn_bbox_loss: 0.4312 - mrcnn_mask_loss: 0.0119 - val_loss: 9.4361 - val_rpn_class_loss: 3.0580 - val_rpn_bbox_loss: 1.6806 - val_mrcnn_class_loss: 0.6046 - val_mrcnn_bbox_loss: 0.7363 - val_mrcnn_mask_loss: 3.3566\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 3615s 40s/step - loss: 1.5795 - rpn_class_loss: 0.1510 - rpn_bbox_loss: 0.6616 - mrcnn_class_loss: 0.2937 - mrcnn_bbox_loss: 0.4621 - mrcnn_mask_loss: 0.0109 - val_loss: 9.6892 - val_rpn_class_loss: 3.4728 - val_rpn_bbox_loss: 1.7548 - val_mrcnn_class_loss: 0.6577 - val_mrcnn_bbox_loss: 0.8175 - val_mrcnn_mask_loss: 2.9864\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 3701s 41s/step - loss: 1.6829 - rpn_class_loss: 0.1582 - rpn_bbox_loss: 0.7677 - mrcnn_class_loss: 0.3013 - mrcnn_bbox_loss: 0.4447 - mrcnn_mask_loss: 0.0110 - val_loss: 8.9217 - val_rpn_class_loss: 2.9681 - val_rpn_bbox_loss: 1.6547 - val_mrcnn_class_loss: 0.5795 - val_mrcnn_bbox_loss: 0.7223 - val_mrcnn_mask_loss: 2.9971\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 3606s 40s/step - loss: 1.3362 - rpn_class_loss: 0.0900 - rpn_bbox_loss: 0.5539 - mrcnn_class_loss: 0.2740 - mrcnn_bbox_loss: 0.4080 - mrcnn_mask_loss: 0.0103 - val_loss: 9.1426 - val_rpn_class_loss: 3.1169 - val_rpn_bbox_loss: 1.7159 - val_mrcnn_class_loss: 0.2936 - val_mrcnn_bbox_loss: 0.7769 - val_mrcnn_mask_loss: 3.2393\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 3666s 41s/step - loss: 1.7370 - rpn_class_loss: 0.2246 - rpn_bbox_loss: 0.7672 - mrcnn_class_loss: 0.2863 - mrcnn_bbox_loss: 0.4490 - mrcnn_mask_loss: 0.0099 - val_loss: 9.7869 - val_rpn_class_loss: 3.1199 - val_rpn_bbox_loss: 1.8889 - val_mrcnn_class_loss: 0.3352 - val_mrcnn_bbox_loss: 0.8076 - val_mrcnn_mask_loss: 3.6353\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 3672s 41s/step - loss: 1.4784 - rpn_class_loss: 0.1491 - rpn_bbox_loss: 0.6195 - mrcnn_class_loss: 0.2726 - mrcnn_bbox_loss: 0.4263 - mrcnn_mask_loss: 0.0108 - val_loss: 9.1603 - val_rpn_class_loss: 3.1522 - val_rpn_bbox_loss: 1.7626 - val_mrcnn_class_loss: 0.2526 - val_mrcnn_bbox_loss: 0.7873 - val_mrcnn_mask_loss: 3.2055\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 3775s 42s/step - loss: 1.8714 - rpn_class_loss: 0.2579 - rpn_bbox_loss: 0.9315 - mrcnn_class_loss: 0.2686 - mrcnn_bbox_loss: 0.4032 - mrcnn_mask_loss: 0.0103 - val_loss: 10.0667 - val_rpn_class_loss: 2.7105 - val_rpn_bbox_loss: 2.2254 - val_mrcnn_class_loss: 0.6472 - val_mrcnn_bbox_loss: 0.7479 - val_mrcnn_mask_loss: 3.7356\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 3625s 40s/step - loss: 1.4753 - rpn_class_loss: 0.1348 - rpn_bbox_loss: 0.5497 - mrcnn_class_loss: 0.3150 - mrcnn_bbox_loss: 0.4655 - mrcnn_mask_loss: 0.0103 - val_loss: 7.4704 - val_rpn_class_loss: 2.0217 - val_rpn_bbox_loss: 1.5956 - val_mrcnn_class_loss: 0.3118 - val_mrcnn_bbox_loss: 0.8144 - val_mrcnn_mask_loss: 2.7268\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 3663s 41s/step - loss: 1.4789 - rpn_class_loss: 0.1174 - rpn_bbox_loss: 0.6159 - mrcnn_class_loss: 0.3008 - mrcnn_bbox_loss: 0.4330 - mrcnn_mask_loss: 0.0117 - val_loss: 9.0654 - val_rpn_class_loss: 2.6167 - val_rpn_bbox_loss: 1.7572 - val_mrcnn_class_loss: 0.6808 - val_mrcnn_bbox_loss: 0.7495 - val_mrcnn_mask_loss: 3.2612\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 3594s 40s/step - loss: 1.5176 - rpn_class_loss: 0.1710 - rpn_bbox_loss: 0.6225 - mrcnn_class_loss: 0.2933 - mrcnn_bbox_loss: 0.4203 - mrcnn_mask_loss: 0.0105 - val_loss: 9.8638 - val_rpn_class_loss: 3.1771 - val_rpn_bbox_loss: 1.8150 - val_mrcnn_class_loss: 0.7464 - val_mrcnn_bbox_loss: 0.7859 - val_mrcnn_mask_loss: 3.3394\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 3719s 41s/step - loss: 1.6036 - rpn_class_loss: 0.1491 - rpn_bbox_loss: 0.7053 - mrcnn_class_loss: 0.3023 - mrcnn_bbox_loss: 0.4363 - mrcnn_mask_loss: 0.0106 - val_loss: 9.8708 - val_rpn_class_loss: 3.2630 - val_rpn_bbox_loss: 1.9309 - val_mrcnn_class_loss: 0.6093 - val_mrcnn_bbox_loss: 0.8449 - val_mrcnn_mask_loss: 3.2226\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 3596s 40s/step - loss: 1.3846 - rpn_class_loss: 0.1167 - rpn_bbox_loss: 0.5013 - mrcnn_class_loss: 0.3068 - mrcnn_bbox_loss: 0.4476 - mrcnn_mask_loss: 0.0122 - val_loss: 8.6052 - val_rpn_class_loss: 3.1768 - val_rpn_bbox_loss: 1.9924 - val_mrcnn_class_loss: 0.1679 - val_mrcnn_bbox_loss: 0.7150 - val_mrcnn_mask_loss: 2.5530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "90/90 [==============================] - 3717s 41s/step - loss: 1.4972 - rpn_class_loss: 0.0993 - rpn_bbox_loss: 0.6980 - mrcnn_class_loss: 0.2725 - mrcnn_bbox_loss: 0.4161 - mrcnn_mask_loss: 0.0113 - val_loss: 9.5155 - val_rpn_class_loss: 3.1251 - val_rpn_bbox_loss: 1.7677 - val_mrcnn_class_loss: 0.5136 - val_mrcnn_bbox_loss: 0.8057 - val_mrcnn_mask_loss: 3.3032\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 3542s 39s/step - loss: 1.3324 - rpn_class_loss: 0.1136 - rpn_bbox_loss: 0.5107 - mrcnn_class_loss: 0.2840 - mrcnn_bbox_loss: 0.4126 - mrcnn_mask_loss: 0.0115 - val_loss: 9.1916 - val_rpn_class_loss: 2.7863 - val_rpn_bbox_loss: 1.6038 - val_mrcnn_class_loss: 0.5015 - val_mrcnn_bbox_loss: 0.7981 - val_mrcnn_mask_loss: 3.5018\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 3727s 41s/step - loss: 1.6138 - rpn_class_loss: 0.1742 - rpn_bbox_loss: 0.7042 - mrcnn_class_loss: 0.2801 - mrcnn_bbox_loss: 0.4451 - mrcnn_mask_loss: 0.0102 - val_loss: 10.6847 - val_rpn_class_loss: 3.0815 - val_rpn_bbox_loss: 1.8787 - val_mrcnn_class_loss: 0.7346 - val_mrcnn_bbox_loss: 0.8284 - val_mrcnn_mask_loss: 4.1616\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 3593s 40s/step - loss: 1.5453 - rpn_class_loss: 0.1522 - rpn_bbox_loss: 0.6709 - mrcnn_class_loss: 0.2847 - mrcnn_bbox_loss: 0.4274 - mrcnn_mask_loss: 0.0102 - val_loss: 9.5085 - val_rpn_class_loss: 2.9490 - val_rpn_bbox_loss: 1.9597 - val_mrcnn_class_loss: 0.4223 - val_mrcnn_bbox_loss: 0.7719 - val_mrcnn_mask_loss: 3.4055\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 3681s 41s/step - loss: 1.6387 - rpn_class_loss: 0.2036 - rpn_bbox_loss: 0.7380 - mrcnn_class_loss: 0.2557 - mrcnn_bbox_loss: 0.4308 - mrcnn_mask_loss: 0.0106 - val_loss: 10.1943 - val_rpn_class_loss: 2.8130 - val_rpn_bbox_loss: 1.7908 - val_mrcnn_class_loss: 0.4533 - val_mrcnn_bbox_loss: 0.8428 - val_mrcnn_mask_loss: 4.2944\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 3570s 40s/step - loss: 1.5123 - rpn_class_loss: 0.1466 - rpn_bbox_loss: 0.6453 - mrcnn_class_loss: 0.2752 - mrcnn_bbox_loss: 0.4341 - mrcnn_mask_loss: 0.0111 - val_loss: 10.5758 - val_rpn_class_loss: 3.3114 - val_rpn_bbox_loss: 2.1428 - val_mrcnn_class_loss: 0.4094 - val_mrcnn_bbox_loss: 0.8091 - val_mrcnn_mask_loss: 3.9032\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 3694s 41s/step - loss: 1.6896 - rpn_class_loss: 0.1684 - rpn_bbox_loss: 0.7598 - mrcnn_class_loss: 0.3035 - mrcnn_bbox_loss: 0.4476 - mrcnn_mask_loss: 0.0103 - val_loss: 12.1891 - val_rpn_class_loss: 3.5320 - val_rpn_bbox_loss: 3.0183 - val_mrcnn_class_loss: 0.3933 - val_mrcnn_bbox_loss: 0.8889 - val_mrcnn_mask_loss: 4.3565\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 3649s 41s/step - loss: 1.4355 - rpn_class_loss: 0.1304 - rpn_bbox_loss: 0.5836 - mrcnn_class_loss: 0.2945 - mrcnn_bbox_loss: 0.4169 - mrcnn_mask_loss: 0.0101 - val_loss: 9.4828 - val_rpn_class_loss: 2.9810 - val_rpn_bbox_loss: 2.4694 - val_mrcnn_class_loss: 0.2951 - val_mrcnn_bbox_loss: 0.8815 - val_mrcnn_mask_loss: 2.8558\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 3688s 41s/step - loss: 1.3742 - rpn_class_loss: 0.0829 - rpn_bbox_loss: 0.5803 - mrcnn_class_loss: 0.2875 - mrcnn_bbox_loss: 0.4120 - mrcnn_mask_loss: 0.0115 - val_loss: 10.0571 - val_rpn_class_loss: 3.0951 - val_rpn_bbox_loss: 2.5776 - val_mrcnn_class_loss: 0.3328 - val_mrcnn_bbox_loss: 0.8741 - val_mrcnn_mask_loss: 3.1774\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 3603s 40s/step - loss: 1.7352 - rpn_class_loss: 0.1830 - rpn_bbox_loss: 0.7983 - mrcnn_class_loss: 0.3042 - mrcnn_bbox_loss: 0.4384 - mrcnn_mask_loss: 0.0112 - val_loss: 10.6058 - val_rpn_class_loss: 2.8521 - val_rpn_bbox_loss: 2.2135 - val_mrcnn_class_loss: 0.3576 - val_mrcnn_bbox_loss: 0.8573 - val_mrcnn_mask_loss: 4.3253\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 3646s 41s/step - loss: 1.5833 - rpn_class_loss: 0.1170 - rpn_bbox_loss: 0.7453 - mrcnn_class_loss: 0.2955 - mrcnn_bbox_loss: 0.4142 - mrcnn_mask_loss: 0.0111 - val_loss: 9.9306 - val_rpn_class_loss: 3.0269 - val_rpn_bbox_loss: 2.2195 - val_mrcnn_class_loss: 0.3274 - val_mrcnn_bbox_loss: 0.8608 - val_mrcnn_mask_loss: 3.4960\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 3623s 40s/step - loss: 1.4153 - rpn_class_loss: 0.1284 - rpn_bbox_loss: 0.6110 - mrcnn_class_loss: 0.2684 - mrcnn_bbox_loss: 0.3967 - mrcnn_mask_loss: 0.0107 - val_loss: 11.3878 - val_rpn_class_loss: 3.1664 - val_rpn_bbox_loss: 2.7988 - val_mrcnn_class_loss: 0.2546 - val_mrcnn_bbox_loss: 0.8911 - val_mrcnn_mask_loss: 4.2770\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 3678s 41s/step - loss: 1.6448 - rpn_class_loss: 0.1450 - rpn_bbox_loss: 0.7646 - mrcnn_class_loss: 0.2814 - mrcnn_bbox_loss: 0.4429 - mrcnn_mask_loss: 0.0109 - val_loss: 10.3733 - val_rpn_class_loss: 2.8278 - val_rpn_bbox_loss: 2.0320 - val_mrcnn_class_loss: 0.3796 - val_mrcnn_bbox_loss: 0.8502 - val_mrcnn_mask_loss: 4.2837\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 3652s 41s/step - loss: 1.5231 - rpn_class_loss: 0.1696 - rpn_bbox_loss: 0.6630 - mrcnn_class_loss: 0.2718 - mrcnn_bbox_loss: 0.4082 - mrcnn_mask_loss: 0.0106 - val_loss: 10.1541 - val_rpn_class_loss: 2.7564 - val_rpn_bbox_loss: 1.8744 - val_mrcnn_class_loss: 0.5392 - val_mrcnn_bbox_loss: 0.8075 - val_mrcnn_mask_loss: 4.1765\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 3620s 40s/step - loss: 1.4022 - rpn_class_loss: 0.1170 - rpn_bbox_loss: 0.5756 - mrcnn_class_loss: 0.2634 - mrcnn_bbox_loss: 0.4360 - mrcnn_mask_loss: 0.0102 - val_loss: 10.1416 - val_rpn_class_loss: 2.7797 - val_rpn_bbox_loss: 2.0072 - val_mrcnn_class_loss: 0.2305 - val_mrcnn_bbox_loss: 0.8219 - val_mrcnn_mask_loss: 4.3023\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 3653s 41s/step - loss: 1.3031 - rpn_class_loss: 0.0945 - rpn_bbox_loss: 0.5361 - mrcnn_class_loss: 0.2626 - mrcnn_bbox_loss: 0.3999 - mrcnn_mask_loss: 0.0098 - val_loss: 10.4175 - val_rpn_class_loss: 3.0716 - val_rpn_bbox_loss: 2.0435 - val_mrcnn_class_loss: 0.2772 - val_mrcnn_bbox_loss: 0.8113 - val_mrcnn_mask_loss: 4.2139\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 3678s 41s/step - loss: 1.3796 - rpn_class_loss: 0.1080 - rpn_bbox_loss: 0.5808 - mrcnn_class_loss: 0.2742 - mrcnn_bbox_loss: 0.4061 - mrcnn_mask_loss: 0.0105 - val_loss: 9.2868 - val_rpn_class_loss: 3.4253 - val_rpn_bbox_loss: 2.2905 - val_mrcnn_class_loss: 0.1643 - val_mrcnn_bbox_loss: 0.6638 - val_mrcnn_mask_loss: 2.7428\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 3693s 41s/step - loss: 1.4388 - rpn_class_loss: 0.1391 - rpn_bbox_loss: 0.5938 - mrcnn_class_loss: 0.2741 - mrcnn_bbox_loss: 0.4215 - mrcnn_mask_loss: 0.0102 - val_loss: 9.6480 - val_rpn_class_loss: 3.1656 - val_rpn_bbox_loss: 2.0532 - val_mrcnn_class_loss: 0.2376 - val_mrcnn_bbox_loss: 0.7776 - val_mrcnn_mask_loss: 3.4140\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 3719s 41s/step - loss: 1.2918 - rpn_class_loss: 0.1113 - rpn_bbox_loss: 0.5200 - mrcnn_class_loss: 0.2497 - mrcnn_bbox_loss: 0.4008 - mrcnn_mask_loss: 0.0100 - val_loss: 9.6431 - val_rpn_class_loss: 3.1775 - val_rpn_bbox_loss: 1.7570 - val_mrcnn_class_loss: 0.3225 - val_mrcnn_bbox_loss: 0.9577 - val_mrcnn_mask_loss: 3.4284\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 3601s 40s/step - loss: 1.3050 - rpn_class_loss: 0.1027 - rpn_bbox_loss: 0.5655 - mrcnn_class_loss: 0.2309 - mrcnn_bbox_loss: 0.3952 - mrcnn_mask_loss: 0.0106 - val_loss: 10.2420 - val_rpn_class_loss: 2.7885 - val_rpn_bbox_loss: 1.7981 - val_mrcnn_class_loss: 0.4040 - val_mrcnn_bbox_loss: 0.7914 - val_mrcnn_mask_loss: 4.4599\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 3661s 41s/step - loss: 1.3509 - rpn_class_loss: 0.1126 - rpn_bbox_loss: 0.5503 - mrcnn_class_loss: 0.2460 - mrcnn_bbox_loss: 0.4310 - mrcnn_mask_loss: 0.0110 - val_loss: 9.4554 - val_rpn_class_loss: 3.3337 - val_rpn_bbox_loss: 2.0905 - val_mrcnn_class_loss: 0.2728 - val_mrcnn_bbox_loss: 0.8487 - val_mrcnn_mask_loss: 2.9097\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 3703s 41s/step - loss: 1.2522 - rpn_class_loss: 0.1004 - rpn_bbox_loss: 0.4902 - mrcnn_class_loss: 0.2510 - mrcnn_bbox_loss: 0.4007 - mrcnn_mask_loss: 0.0098 - val_loss: 9.6891 - val_rpn_class_loss: 3.0932 - val_rpn_bbox_loss: 1.8620 - val_mrcnn_class_loss: 0.3138 - val_mrcnn_bbox_loss: 0.8200 - val_mrcnn_mask_loss: 3.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "90/90 [==============================] - 3600s 40s/step - loss: 1.4849 - rpn_class_loss: 0.1667 - rpn_bbox_loss: 0.6546 - mrcnn_class_loss: 0.2377 - mrcnn_bbox_loss: 0.4146 - mrcnn_mask_loss: 0.0113 - val_loss: 9.8203 - val_rpn_class_loss: 2.6167 - val_rpn_bbox_loss: 1.5846 - val_mrcnn_class_loss: 0.4040 - val_mrcnn_bbox_loss: 0.7843 - val_mrcnn_mask_loss: 4.4307\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 3642s 40s/step - loss: 1.5546 - rpn_class_loss: 0.1838 - rpn_bbox_loss: 0.7171 - mrcnn_class_loss: 0.2315 - mrcnn_bbox_loss: 0.4105 - mrcnn_mask_loss: 0.0116 - val_loss: 10.4529 - val_rpn_class_loss: 2.9376 - val_rpn_bbox_loss: 1.9818 - val_mrcnn_class_loss: 0.4167 - val_mrcnn_bbox_loss: 0.8274 - val_mrcnn_mask_loss: 4.2894\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 3702s 41s/step - loss: 1.2870 - rpn_class_loss: 0.0692 - rpn_bbox_loss: 0.5659 - mrcnn_class_loss: 0.2454 - mrcnn_bbox_loss: 0.3954 - mrcnn_mask_loss: 0.0111 - val_loss: 9.7935 - val_rpn_class_loss: 3.2416 - val_rpn_bbox_loss: 2.1176 - val_mrcnn_class_loss: 0.2676 - val_mrcnn_bbox_loss: 0.7824 - val_mrcnn_mask_loss: 3.3843\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 3601s 40s/step - loss: 1.4851 - rpn_class_loss: 0.1769 - rpn_bbox_loss: 0.6555 - mrcnn_class_loss: 0.2436 - mrcnn_bbox_loss: 0.3983 - mrcnn_mask_loss: 0.0108 - val_loss: 9.7934 - val_rpn_class_loss: 2.9580 - val_rpn_bbox_loss: 2.5135 - val_mrcnn_class_loss: 0.2969 - val_mrcnn_bbox_loss: 0.7721 - val_mrcnn_mask_loss: 3.2528\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 3662s 41s/step - loss: 1.4757 - rpn_class_loss: 0.1018 - rpn_bbox_loss: 0.6840 - mrcnn_class_loss: 0.2834 - mrcnn_bbox_loss: 0.3960 - mrcnn_mask_loss: 0.0105 - val_loss: 9.9571 - val_rpn_class_loss: 3.4475 - val_rpn_bbox_loss: 2.7732 - val_mrcnn_class_loss: 0.2361 - val_mrcnn_bbox_loss: 0.7858 - val_mrcnn_mask_loss: 2.7143\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 3651s 41s/step - loss: 1.4222 - rpn_class_loss: 0.1109 - rpn_bbox_loss: 0.6043 - mrcnn_class_loss: 0.2885 - mrcnn_bbox_loss: 0.4075 - mrcnn_mask_loss: 0.0110 - val_loss: 11.6046 - val_rpn_class_loss: 3.6580 - val_rpn_bbox_loss: 3.0851 - val_mrcnn_class_loss: 0.2695 - val_mrcnn_bbox_loss: 0.8634 - val_mrcnn_mask_loss: 3.7286\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 3668s 41s/step - loss: 1.3425 - rpn_class_loss: 0.1331 - rpn_bbox_loss: 0.5362 - mrcnn_class_loss: 0.2609 - mrcnn_bbox_loss: 0.4015 - mrcnn_mask_loss: 0.0107 - val_loss: 10.4397 - val_rpn_class_loss: 3.0102 - val_rpn_bbox_loss: 2.3969 - val_mrcnn_class_loss: 0.4003 - val_mrcnn_bbox_loss: 0.8361 - val_mrcnn_mask_loss: 3.7962\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 3640s 40s/step - loss: 1.5854 - rpn_class_loss: 0.1484 - rpn_bbox_loss: 0.7440 - mrcnn_class_loss: 0.2761 - mrcnn_bbox_loss: 0.4067 - mrcnn_mask_loss: 0.0101 - val_loss: 10.3192 - val_rpn_class_loss: 3.1654 - val_rpn_bbox_loss: 3.9750 - val_mrcnn_class_loss: 0.1817 - val_mrcnn_bbox_loss: 0.6222 - val_mrcnn_mask_loss: 2.3748\n",
      "Epoch 96/100\n",
      "89/90 [============================>.] - ETA: 29s - loss: 1.8104 - rpn_class_loss: 0.2245 - rpn_bbox_loss: 0.9188 - mrcnn_class_loss: 0.2611 - mrcnn_bbox_loss: 0.3960 - mrcnn_mask_loss: 0.0100"
     ]
    }
   ],
   "source": [
    "start_train = time.time()\n",
    "model.train(dataset_train, dataset_val, learning_rate = myMaskRCNNConfig().LEARNING_RATE, epochs = NUM_EPOCHS, layers = 'all',\n",
    "           augmentation = imgaug.augmenters.Sequential([\n",
    "                imgaug.augmenters.Fliplr(1),\n",
    "                imgaug.augmenters.Flipud(1),\n",
    "                imgaug.augmenters.Affine(rotate=(-45, 45)),\n",
    "                imgaug.augmenters.Affine(rotate=(-90, 90)),\n",
    "                imgaug.augmenters.LinearContrast((0.75, 1.5)),\n",
    "                imgaug.augmenters.GaussianBlur(sigma=(0, 0.5)),\n",
    "                imgaug.augmenters.Affine(scale=(0.5, 1.5))\n",
    "            ], random_order=True # apply augmenters in random order\n",
    "            ))\n",
    "end_train = time.time()\n",
    "minutes = round((end_train - start_train) / 60, 2)\n",
    "print(f'Training took {minutes} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
